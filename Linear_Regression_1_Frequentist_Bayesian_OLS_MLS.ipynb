{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPQOaGoQhGGpdaKInRMvEt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvaroEkel/Probabilistic-Machine-Learning_Lecture/blob/main/Linear_Regression_1_Frequentist_Bayesian_OLS_MLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression: Frequentist - Bayesian | OLS - MLS\n",
        "\n",
        "In this notebook, we explore linear regression from both:\n",
        "- **Frequentist**: Point estimates via Maximum Likelihood.\n",
        "- **Bayesian**: Prior, posterior, and predictive distribution.\n",
        "\n",
        "and\n",
        "\n",
        "- **Ordinary Linear Regression** (OLS) (one variable)\n",
        "- **Multiple Linear Regression** (MLS) (multiple variables)\n",
        ""
      ],
      "metadata": {
        "id": "v8jNjO2UEIf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpjnumdg9pIV"
      },
      "outputs": [],
      "source": [
        "# Linear Regression on the Boston Housing Dataset\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import statsmodels.api as sm\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "# Load dataset\n",
        "boston = load_boston()\n",
        "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "df['MEDV'] = boston.target\n",
        "\n",
        "# --- FREQUENTIST SINGLE REGRESSION: MEDV vs RM ---\n",
        "X = df[['RM']]\n",
        "y = df['MEDV']\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())\n",
        "\n",
        "# Plot\n",
        "sns.regplot(x='RM', y='MEDV', data=df)\n",
        "plt.title('Linear Regression: MEDV vs RM')\n",
        "plt.show()\n",
        "\n",
        "# --- FREQUENTIST MULTIPLE REGRESSION ---\n",
        "X = df.drop('MEDV', axis=1)\n",
        "y = df['MEDV']\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())\n",
        "\n",
        "# --- BAYESIAN SINGLE REGRESSION: MEDV vs RM ---\n",
        "X = df[['RM']].values.flatten()\n",
        "y = df['MEDV'].values\n",
        "\n",
        "with pm.Model() as model_bayes_single:\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
        "    beta = pm.Normal('beta', mu=0, sigma=1)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=5)\n",
        "    mu = alpha + beta * X\n",
        "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
        "    trace = pm.sample(1000, tune=1000, return_inferencedata=True)\n",
        "\n",
        "az.plot_trace(trace)\n",
        "plt.show()\n",
        "\n",
        "# --- BAYESIAN MULTIPLE REGRESSION ---\n",
        "X = df.drop('MEDV', axis=1)\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "y = df['MEDV'].values\n",
        "\n",
        "with pm.Model() as model_bayes_multi:\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
        "    betas = pm.Normal('betas', mu=0, sigma=1, shape=X.shape[1])\n",
        "    sigma = pm.HalfNormal('sigma', sigma=5)\n",
        "    mu = alpha + pm.math.dot(X_scaled, betas)\n",
        "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
        "    trace_multi = pm.sample(1000, tune=1000, return_inferencedata=True)\n",
        "\n",
        "az.plot_trace(trace_multi, var_names=['alpha', 'betas'])\n",
        "plt.show()\n",
        "\n",
        "# Posterior predictive checks\n",
        "with model_bayes_multi:\n",
        "    ppc = pm.sample_posterior_predictive(trace_multi, var_names=['y_obs'])\n",
        "az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=model_bayes_multi))\n",
        "plt.show()\n"
      ]
    }
  ]
}