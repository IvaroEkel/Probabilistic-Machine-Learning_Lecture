{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPmyva8cKHtep+zC3RS3kuO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvaroEkel/Probabilistic-Machine-Learning_Lecture/blob/main/Linear_Regression_1_Frequentist_Bayesian_OLS_MLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression: Frequentist - Bayesian | OLS - MLS\n",
        "\n",
        "In this notebook, we explore linear regression from both:\n",
        "- **Frequentist**: Point estimates via Maximum Likelihood.\n",
        "- **Bayesian**: Prior, posterior, and predictive distribution.\n",
        "\n",
        "and\n",
        "\n",
        "- **Ordinary Linear Regression** (OLS) (one variable)\n",
        "- **Multiple Linear Regression** (MLS) (multiple variables)\n"
      ],
      "metadata": {
        "id": "v8jNjO2UEIf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression on an example of ML fairness: the Boston Housing Dataset"
      ],
      "metadata": {
        "id": "pUyGj0WUqek_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c_sWtEry-8ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import statsmodels.api as sm\n",
        "import pymc as pm\n",
        "import arviz as az\n"
      ],
      "metadata": {
        "id": "Wiscff-5qgKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston"
      ],
      "metadata": {
        "id": "h8czlynMHr_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "    # data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :3]])\n",
        "    target = raw_df.values[1::2, 2]\n"
      ],
      "metadata": {
        "id": "TmfY9RU-qvlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        " prices and the demand for clean air', J. Environ. Economics & Management,\n",
        " vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        " ...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        " pages 244-261 of the latter.\n",
        "\n",
        "**Variables in order**:\n",
        "  - CRIM     per capita crime rate by town\n",
        "  - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "  - INDUS    proportion of non-retail business acres per town\n",
        "  - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "  - NOX      nitric oxides concentration (parts per 10 million)\n",
        "  - RM       average number of rooms per dwelling\n",
        "  - AGE      proportion of owner-occupied units built prior to 1940\n",
        "  - DIS      weighted distances to five Boston employment centres\n",
        "  - RAD      index of accessibility to radial highways\n",
        "  - TAX      full-value property-tax rate per $10,000$ usd\n",
        "  - PTRATIO  pupil teacher ratio by town\n",
        "  - B        $1000(B_k - 0.63)^2$ where $B_k$ is the proportion of blacks by town\n",
        "  - LSTAT    $%$ lower status of the population\n",
        "  - MEDV     Median value of owner-occupied homes in $1000's"
      ],
      "metadata": {
        "id": "NusbfwjotZrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_col_names = [\n",
        "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
        "    'PTRATIO', 'B', 'LSTAT', 'MEDV'\n",
        "]\n",
        "len(new_col_names)\n"
      ],
      "metadata": {
        "id": "zDSv-OskuLf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data,columns= new_col_names)\n",
        "df"
      ],
      "metadata": {
        "id": "S3xPrmAfq2gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FREQUENTIST REGRESSION: MEDV vs RM ---"
      ],
      "metadata": {
        "id": "5RqgPr9DIUaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['RM']]\n",
        "y = df['MEDV']\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "gBw_XourIWZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot\n",
        "sns.regplot(x='RM', y='MEDV', data=df)\n",
        "plt.title('Linear Regression: MEDV vs RM')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LIBJgksaItZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FREQUENTIST MULTIPLE REGRESSION ---"
      ],
      "metadata": {
        "id": "Bepyg0pIJFRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['MEDV']\n",
        "X = df.drop('MEDV', axis=1)\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "bMmCi4ygK7P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- BAYESIAN SINGLE REGRESSION: MEDV vs RM ---"
      ],
      "metadata": {
        "id": "kyvU_KxVVTEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['RM']].values.flatten()\n",
        "y = df['MEDV'].values\n",
        "\n",
        "with pm.Model() as model_bayes_single:\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
        "    beta = pm.Normal('beta', mu=0, sigma=1)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=5)\n",
        "    mu = alpha + beta * X\n",
        "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
        "    trace = pm.sample(1000, tune=1000, return_inferencedata=True)\n",
        "\n",
        "az.plot_trace(trace)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FzsjmCD6VRld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# --- BAYESIAN MULTIPLE REGRESSION ---"
      ],
      "metadata": {
        "id": "-1WU7uVxVl_P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpjnumdg9pIV"
      },
      "outputs": [],
      "source": [
        "X = df.drop('MEDV', axis=1)\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "y = df['MEDV'].values\n",
        "\n",
        "with pm.Model() as model_bayes_multi:\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
        "    betas = pm.Normal('betas', mu=0, sigma=1, shape=X.shape[1])\n",
        "    sigma = pm.HalfNormal('sigma', sigma=5)\n",
        "    mu = alpha + pm.math.dot(X_scaled, betas)\n",
        "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
        "    trace_multi = pm.sample(1000, tune=1000, return_inferencedata=True)\n",
        "\n",
        "az.plot_trace(trace_multi, var_names=['alpha', 'betas'])\n",
        "plt.show()\n",
        "\n",
        "# Posterior predictive checks\n",
        "with model_bayes_multi:\n",
        "    ppc = pm.sample_posterior_predictive(trace_multi, var_names=['y_obs'])\n",
        "# az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=model_bayes_multi))\n",
        "# plt.show()\n",
        "# Remove the conversion using from_pymc3 since it's not needed.\n",
        "# Replace line 19 with the following:\n",
        "az.plot_ppc(trace_multi, group=\"posterior_predictive\", var_names=['y_obs'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GyU3JWzJk2VW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}