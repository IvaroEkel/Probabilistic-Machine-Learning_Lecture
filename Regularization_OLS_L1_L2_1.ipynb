{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNmH6S5Y/7Jiu4gjwmcIIQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvaroEkel/Probabilistic-Machine-Learning_Lecture/blob/main/Regularization_OLS_L1_L2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes, fetch_california_housing\n",
        "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "sLIumvWbgThb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load datasets\n",
        "diabetes = load_diabetes()\n",
        "X_diabetes, y_diabetes = diabetes.data, diabetes.target\n",
        "feature_names = diabetes.feature_names\n",
        "california = fetch_california_housing()\n",
        "X_california, y_california = california.data, california.target\n",
        "\n",
        "# Create DataFrame for better feature handling\n",
        "diabetes_df = pd.DataFrame(X_diabetes, columns=feature_names)\n",
        "california_df = pd.DataFrame(X_california)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_diabetes = scaler.fit_transform(X_diabetes)\n",
        "X_california = scaler.fit_transform(X_california)\n",
        "\n",
        "# Train-test split\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_diabetes, y_diabetes, test_size=0.3, random_state=42)\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_california, y_california, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "xiRCVDNQgW9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to fit models and compare\n",
        "def compare_l1_l2(X_train, X_test, y_train, y_test, dataset_name):\n",
        "    alphas = np.logspace(-2, 3, 40)\n",
        "    lasso_mse = []\n",
        "    ridge_mse = []\n",
        "\n",
        "    for alpha in alphas:\n",
        "        lasso = Lasso(alpha=alpha, max_iter=10000)\n",
        "        ridge = Ridge(alpha=alpha)\n",
        "\n",
        "        lasso.fit(X_train, y_train)\n",
        "        ridge.fit(X_train, y_train)\n",
        "\n",
        "        y_pred_lasso = lasso.predict(X_test)\n",
        "        y_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "        lasso_mse.append(mean_squared_error(y_test, y_pred_lasso))\n",
        "        ridge_mse.append(mean_squared_error(y_test, y_pred_ridge))\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(alphas, lasso_mse, label='Lasso (L1)', marker='o')\n",
        "    plt.plot(alphas, ridge_mse, label='Ridge (L2)', marker='x')\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Regularization strength (alpha)')\n",
        "    plt.ylabel('Mean Squared Error (MSE)')\n",
        "    plt.title(f'Comparison of L1 and L2 Regularization on {dataset_name} Dataset')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nBest Lasso (L1) MSE for {dataset_name}: {np.min(lasso_mse):.3f} at alpha={alphas[np.argmin(lasso_mse)]:.3f}\")\n",
        "    print(f\"Best Ridge (L2) MSE for {dataset_name}: {np.min(ridge_mse):.3f} at alpha={alphas[np.argmin(ridge_mse)]:.3f}\")\n",
        "\n",
        "# Run comparison\n",
        "compare_l1_l2(X_train_d, X_test_d, y_train_d, y_test_d, \"Diabetes\")\n"
      ],
      "metadata": {
        "id": "VLoeSsQagYnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extra: visualize coefficients shrinkage\n",
        "alpha = 1.0\n",
        "lasso = Lasso(alpha=alpha, max_iter=10000)\n",
        "ridge = Ridge(alpha=alpha)\n",
        "linear = LinearRegression()\n",
        "\n",
        "lasso.fit(X_train_d, y_train_d)\n",
        "ridge.fit(X_train_d, y_train_d)\n",
        "linear.fit(X_train_d, y_train_d)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(lasso.coef_, label='Lasso coefficients', marker='o')\n",
        "plt.plot(ridge.coef_, label='Ridge coefficients', marker='x')\n",
        "plt.plot(linear.coef_, label='Linear Regression coefficients', marker='^')\n",
        "plt.xlabel('Feature Index')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.axhline(0, color='black', linewidth=0.8)\n",
        "plt.title('Coefficient Comparison (Diabetes dataset)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lzTQ6l5PgcRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGpNbTZ3gDKi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualization of level surfaces and coefficient paths\n",
        "alphas = np.logspace(-2, 2, 30)\n",
        "coeffs_lasso = []\n",
        "coeffs_ridge = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    lasso.fit(X_train_d[:, :2], y_train_d)  # Using only the first two features: feature_names[0] and feature_names[1]\n",
        "    ridge.fit(X_train_d[:, :2], y_train_d)\n",
        "    coeffs_lasso.append(lasso.coef_)\n",
        "    coeffs_ridge.append(ridge.coef_)\n",
        "\n",
        "coeffs_lasso = np.array(coeffs_lasso)\n",
        "coeffs_ridge = np.array(coeffs_ridge)\n",
        "\n",
        "df_coeffs_lasso = pd.DataFrame(coeffs_lasso, columns=feature_names[:2])\n",
        "df_coeffs_ridge = pd.DataFrame(coeffs_ridge, columns=feature_names[:2])\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "x = np.linspace(-1, 1, 100)\n",
        "y = np.linspace(-1, 1, 100)\n",
        "X_grid, Y_grid = np.meshgrid(x, y)\n",
        "\n",
        "# L1 norm contour\n",
        "Z1 = np.abs(X_grid) + np.abs(Y_grid)\n",
        "axs[0].contour(X_grid, Y_grid, Z1, levels=[0.5, 1, 1.5], colors='blue')\n",
        "axs[0].plot(coeffs_lasso[:, 0], coeffs_lasso[:, 1], marker='o', label='Lasso path', color='black')\n",
        "axs[0].set_title(f'L1-norm constraint and Coefficient Path (Lasso)\\n({feature_names[0]} vs {feature_names[1]})')\n",
        "axs[0].set_xlabel(f'Coefficient for {feature_names[0]}')\n",
        "axs[0].set_ylabel(f'Coefficient for {feature_names[1]}')\n",
        "axs[0].grid(True)\n",
        "axs[0].axhline(0, color='black', lw=0.5)\n",
        "axs[0].axvline(0, color='black', lw=0.5)\n",
        "axs[0].set_aspect('equal')\n",
        "axs[0].legend()\n",
        "\n",
        "# L2 norm contour\n",
        "Z2 = np.sqrt(X_grid**2 + Y_grid**2)\n",
        "axs[1].contour(X_grid, Y_grid, Z2, levels=[0.5, 1, 1.5], colors='red')\n",
        "axs[1].plot(coeffs_ridge[:, 0], coeffs_ridge[:, 1], marker='x', label='Ridge path', color='black')\n",
        "axs[1].set_title(f'L2-norm constraint and Coefficient Path (Ridge)\\n({feature_names[0]} vs {feature_names[1]})')\n",
        "axs[1].set_xlabel(f'Coefficient for {feature_names[0]}')\n",
        "axs[1].set_ylabel(f'Coefficient for {feature_names[1]}')\n",
        "axs[1].grid(True)\n",
        "axs[1].axhline(0, color='black', lw=0.5)\n",
        "axs[1].axvline(0, color='black', lw=0.5)\n",
        "axs[1].set_aspect('equal')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_coeffs_lasso"
      ],
      "metadata": {
        "id": "XKDJfBgZi0wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explicitly fit models for 5 alphas\n",
        "selected_alphas = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "for alpha in selected_alphas:\n",
        "    print(f\"\\nAlpha = {alpha}\")\n",
        "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    linear = LinearRegression()\n",
        "\n",
        "    lasso.fit(X_train_d, y_train_d)\n",
        "    ridge.fit(X_train_d, y_train_d)\n",
        "    linear.fit(X_train_d, y_train_d)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'OLS': linear.coef_,\n",
        "        f'Lasso (alpha={alpha})': lasso.coef_,\n",
        "        f'Ridge (alpha={alpha})': ridge.coef_\n",
        "    })\n",
        "\n",
        "    print(df.round(3))\n"
      ],
      "metadata": {
        "id": "srhrmuJRgP7m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}